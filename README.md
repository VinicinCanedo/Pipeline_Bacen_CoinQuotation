# üí± Projeto de Pipeline de Dados - Cota√ß√µes de Moedas (BACEN)

**Objetivo principal:**  
Executar um pipeline ETL que coleta, transforma e disponibiliza dados para an√°lise da **cota√ß√£o do D√≥lar (USD) em rela√ß√£o ao Real (BRL)**, apresentando suas cota√ß√µes di√°rias, taxas de c√¢mbio e o status dos boletins di√°rios.

Este projeto implementa um pipeline de dados completo que coleta, transforma, armazena e apresenta visualmente as **cota√ß√µes di√°rias do D√≥lar (USD)** por meio da API p√∫blica do Banco Central do Brasil (BACEN).

## üß† Vis√£o Geral

A solu√ß√£o automatiza o processo de obten√ß√£o de cota√ß√µes cambiais e torna os dados acess√≠veis de forma visual e interativa via dashboard. O pipeline √© orquestrado para rodar diariamente de forma autom√°tica, buscando apenas os dados mais recentes para otimizar o processo.

---

## üß∞ Tecnologias Utilizadas

| Etapa | Ferramenta | Descri√ß√£o |
| --- | --- | --- |
| Dados Externos | API BACEN | Fonte de dados de c√¢mbio em tempo real |
| Linguagem | `Python` | Linguagem principal para o desenvolvimento do pipeline e dashboard |
| Depend√™ncias | `Poetry` | Gerenciamento de depend√™ncias do pipeline ETL |
| Extract | `requests` | Coleta os dados da API REST do BACEN |
| Transform | `Python` | Normaliza√ß√£o e tratamento dos dados coletados |
| Load | `Supabase` | Banco de dados relacional (PostgreSQL) na nuvem |
| Dashboard | `Streamlit` | Visualiza√ß√£o e an√°lise interativa em tempo real |
| Orquestra√ß√£o | `GitHub Actions` | Automa√ß√£o e agendamento da execu√ß√£o di√°ria do pipeline |
| Containeriza√ß√£o | `Docker` | Empacotamento e execu√ß√£o isolada do pipeline e do dashboard |

---

## ‚öôÔ∏è Configura√ß√£o do Ambiente

Antes de executar o projeto, siga estes passos para configurar o banco de dados e as credenciais.

### 1. Configurando o Supabase (Banco de Dados)

Voc√™ precisar√° de uma conta gratuita no [Supabase](https://supabase.com/).

**Passo 1: Crie um novo projeto**
- Ap√≥s fazer login, clique em "New project".
- Escolha um nome para o projeto e gere uma senha segura para o banco de dados. Guarde essa senha.
- Selecione a regi√£o mais pr√≥xima de voc√™ e clique em "Create new project".

**Passo 2: Crie a tabela de cota√ß√µes**
- No menu lateral esquerdo, v√° para **SQL Editor**.
- Clique em **New query**.
- Copie e cole o script SQL abaixo e clique em **RUN**. Isso criar√° a tabela `DollarQuotation` com a estrutura correta.


```sql
CREATE TABLE "DollarQuotation" (
    "paridadeCompra" float8,
    "paridadeVenda" float8,
    "cotacaoCompra" float8,
    "cotacaoVenda" float8,
    "dataHoraCotacao" timestamp with time zone NOT NULL,
    "tipoBoletim" text,
    CONSTRAINT "DollarQuotation_pkey" PRIMARY KEY ("dataHoraCotacao")
);
```

**Passo 3: Obtenha a URL e a Chave de API**
- No menu lateral esquerdo, v√° para **Project Settings** (√≠cone de engrenagem).
- Selecione **API**.
- Voc√™ encontrar√° as informa√ß√µes que precisa:
    - Em **Project URL**, copie a URL.
    - Em **Project API Keys**, copie a chave `service_role`. **Aten√ß√£o:** esta chave tem privil√©gios de administrador. Mantenha-a segura e n√£o a exponha publicamente.

### 2. Configurando o Pipeline (Arquivo `.env`)

O pipeline ETL usa um arquivo `.env` para se conectar ao Supabase.

- Na raiz do seu projeto, crie um arquivo chamado `.env`.
- Adicione a URL e a chave que voc√™ copiou no passo anterior:

```properties
# filepath: .env
SUPABASE_URL="SUA_URL_DO_SUPABASE_AQUI"
SUPABASE_KEY="SUA_CHAVE_SERVICE_ROLE_AQUI"
```

### 3. Configurando o Dashboard (`secrets.toml`)

O dashboard Streamlit usa um arquivo de segredos para se conectar de forma segura.

- Na raiz do seu projeto, crie uma pasta chamada `.streamlit`.
- Dentro da pasta `.streamlit`, crie um arquivo chamado `secrets.toml`.
- Adicione as mesmas credenciais do Supabase a este arquivo:

```toml
# filepath: .streamlit/secrets.toml
SUPABASE_URL="SUA_URL_DO_SUPABASE_AQUI"
SUPABASE_KEY="SUA_CHAVE_SERVICE_ROLE_AQUI"
```
**Importante:** Certifique-se de que este arquivo est√° salvo com a codifica√ß√£o **UTF-8**. No VS Code, voc√™ pode verificar e alterar a codifica√ß√£o na barra de status inferior direita.

---

## üê≥ Como Executar com Docker

Com o ambiente configurado, voc√™ pode construir e executar as aplica√ß√µes com os seguintes comandos.

**1. Construa a imagem do Pipeline ETL:**
Este comando usa o `Dockerfile` principal para criar a imagem que executar√° o script de extra√ß√£o.

```bash
docker build -f Dockerfile -t pipeline-bacen .
```

**2. Execute o Pipeline ETL:**
Este comando executa o container, injetando as credenciais do seu arquivo `.env`. O pipeline buscar√° os dados e os salvar√° no seu banco Supabase.

```bash
docker run --env-file .env pipeline-bacen
```

**3. Construa a imagem do Dashboard:**
Este comando usa o `Dockerfile.dashboard` para criar a imagem que servir√° a aplica√ß√£o Streamlit.

```bash
docker build -f Dockerfile.dashboard -t dashboard-bacen .
```

**4. Inicie o Dashboard Streamlit:**
Este comando executa o container do dashboard e mapeia a porta `8501` para que voc√™ possa acess√°-lo no seu navegador.

```bash
docker run -p 8501:8501 dashboard-bacen
```

- Ap√≥s executar, acesse **`http://localhost:8501`** no seu navegador para ver o dashboard.

---

## üîÅ Etapas da Pipeline

1.  **Extra√ß√£o de Dados**
    O pipeline consulta o Supabase para obter a data do √∫ltimo registro. Em seguida, busca na API do BACEN apenas os dados a partir dessa data at√© o dia atual, otimizando a coleta.

2.  **Transforma√ß√£o de Dados**
    Os dados brutos em JSON s√£o processados com Python: os tipos de dados s√£o corrigidos, e duplicatas na mesma carga s√£o removidas para garantir a integridade.

3.  **Carga em Supabase**
    Antes de inserir, o pipeline verifica novamente quais registros j√° existem no banco para evitar erros de duplicidade. Apenas os dados 100% novos s√£o carregados na tabela `DollarQuotation`.

4.  **Visualiza√ß√£o via Streamlit**
    O dashboard se conecta diretamente ao Supabase, garantindo que os dados exibidos estejam sempre atualizados. Ele oferece gr√°ficos de linha, barras e m√©dias m√≥veis, com filtros interativos.